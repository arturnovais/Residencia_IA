{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd460f95",
   "metadata": {},
   "source": [
    "## Experimento de Shannon\n",
    "\n",
    "O notebook a seguir é uma réplica do experimento de Claude Shannon (usando computação) destacado no seu artigo A Mathematical Theory of Communication de 1948.\n",
    "\n",
    "- O experimento consiste em gerar sequências de texto com graus variados de sofisticação estatística para ilustrar como diferentes ordens de n-gramas (ideia de Markov) alteram a similaridade com o inglês real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b738521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependências\n",
    "import re\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb2e67",
   "metadata": {},
   "source": [
    "## Carregando dados\n",
    "\n",
    "O conjunto de dados escolhido foi um coleção de livros em inglês, onde iremos normalizar o texto para facilitar o processo estatístico de contabilizar os grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa167a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_hf = \"books\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9741da2",
   "metadata": {},
   "source": [
    "### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "526d5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manter_letras_e_espacos(texto: str) -> str:\n",
    "    if texto is None:\n",
    "        return \"\"\n",
    "    s = str(texto).lower()\n",
    "    return re.sub(r\"[^a-z ]+\", \"\", s)\n",
    "\n",
    "def adicionar_coluna_normalizada(exemplo):\n",
    "    exemplo[\"texto_normalizado\"] = manter_letras_e_espacos(exemplo.get(\"text\", \"\"))\n",
    "    return exemplo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e9a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ubaada/booksum-complete-cleaned\", config_hf, split=split)\n",
    "dataset = dataset.map(adicionar_coluna_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_corpus(ds, coluna: str, max_docs: Optional[int] = 200) -> str:\n",
    "    n = len(ds) if max_docs is None else min(max_docs, len(ds))\n",
    "    return \" \".join(ds[i][coluna] for i in range(n) if ds[i][coluna])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ac630e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do corpus: 69863990\n"
     ]
    }
   ],
   "source": [
    "alfabeto = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "corpus = juntar_corpus(dataset, \"texto_normalizado\", max_docs=200)\n",
    "print(f\"Tamanho do corpus: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339de52f",
   "metadata": {},
   "source": [
    "## Experiemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e370c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alfabeto = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "tamanho = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426d214",
   "metadata": {},
   "source": [
    "### Amostras aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c0c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amostrar_caracteres_equiprovaveis(alfabeto: List[str], tamanho: int, seed: Optional[int] = None) -> str:\n",
    "    rng = random.Random(seed) if seed is not None else random\n",
    "    return \"\".join(rng.choice(alfabeto) for _ in range(tamanho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a23f9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udaxihhexdvxrcsnbacghqtargwuwrnhosizayzfwnkiegykdcmdlltizbxordmcrj utlsgwcbvhyjchdmiou lfllgviwvuctufrxhfomiuwrhvk yybh bzkmicgswkgupmuoeiehxrrixsnsmlheqpcybdeufzvntcmmtoqiravxdvryiyukdjnfoaxxiqyfqduj\n"
     ]
    }
   ],
   "source": [
    "amostra = amostrar_caracteres_equiprovaveis(alfabeto, tamanho=tamanho, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c864f",
   "metadata": {},
   "source": [
    "Aqui é possível perceber que o aleatório é realmente aleatório rsrs, mas não parece seguir nenhum \"padrão\" da linguagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3cd1d",
   "metadata": {},
   "source": [
    "### Trabalhando com cadeias de markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6326a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_unigramas(texto: str) -> Counter:\n",
    "    return Counter(ch for ch in texto)\n",
    "\n",
    "def treinar_ngramas(texto: str, n: int) -> Tuple[Dict[str, Counter], Counter]:\n",
    "    assert n >= 1\n",
    "    unigr = treinar_unigramas(texto)\n",
    "    if n == 1:\n",
    "        return {}, unigr\n",
    "    modelo = defaultdict(Counter)\n",
    "    janela = n - 1\n",
    "    for i in range(len(texto) - janela):\n",
    "        contexto = texto[i:i+janela]\n",
    "        prox = texto[i+janela]\n",
    "        modelo[contexto][prox] += 1\n",
    "    return dict(modelo), unigr\n",
    "\n",
    "def amostrar_com_pesos(contagens: Counter, rng: random.Random) -> str:\n",
    "    simbolos = list(contagens.keys())\n",
    "    pesos = list(contagens.values())\n",
    "    return rng.choices(simbolos, weights=pesos, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc03d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolher_contexto_inicial(modelo: Dict[str, Counter], janela: int, rng: random.Random) -> str:\n",
    "    if modelo:\n",
    "        return rng.choice(list(modelo.keys()))\n",
    "    return \" \" * janela\n",
    "\n",
    "def amostrar_markov(modelo: Dict[str, Counter],\n",
    "                    unigr: Counter,\n",
    "                    n: int,\n",
    "                    tamanho: int,\n",
    "                    alfabeto: List[str],\n",
    "                    seed: Optional[int] = None) -> str:\n",
    "    rng = random.Random(seed) if seed is not None else random\n",
    "    if n == 1:\n",
    "        return \"\".join(rng.choices(list(unigr.keys()) or alfabeto, weights=list(unigr.values()) or None, k=tamanho))\n",
    "    janela = n - 1\n",
    "    contexto = escolher_contexto_inicial(modelo, janela, rng)\n",
    "    saida = []\n",
    "    for _ in range(tamanho):\n",
    "        contagens = modelo.get(contexto)\n",
    "        if not contagens:\n",
    "            for j in range(1, janela):\n",
    "                subctx = contexto[j:]\n",
    "                contagens = modelo.get(subctx)\n",
    "                if contagens:\n",
    "                    break\n",
    "        if not contagens:\n",
    "            if unigr:\n",
    "                saida.append(amostrar_com_pesos(unigr, rng))\n",
    "            else:\n",
    "                saida.append(rng.choice(alfabeto))\n",
    "        else:\n",
    "            prox = amostrar_com_pesos(contagens, rng)\n",
    "            saida.append(prox)\n",
    "        contexto = (contexto + saida[-1])[-janela:]\n",
    "    return \"\".join(saida)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c444f",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888bfac",
   "metadata": {},
   "source": [
    "Para esse experimento, iremos olhar apenas quantas vezes cada caracter apareceu no corpus, sem considerar dependência entre caractéres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "123aa36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toi edw ao so tr tcbcem gf  htceryarhthreo ik  itaa iltt e aptrdhe oii guidaln  r twa js o teaoapsyhbedrit nngu s luitt eresbfoluhioug soee nr ua re iptns  ft  ot who d  lrnec  nanedp afh  nai lnhroxh\n"
     ]
    }
   ],
   "source": [
    "n=1\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08a85a",
   "metadata": {},
   "source": [
    "Nesse ponto, podemos ver que parece que temos ideia de \"palavras\", onde espaços aparecem, mas de maneira muito \"sem sentido\" ainda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b177cc",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84412e9d",
   "metadata": {},
   "source": [
    "Agora a probabilidade de cada letra é considerada dado a letra anterior, ou seja, quantas vezes aquela letra aparece após a que veio anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cac1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es ofains fo rd thif thes alll t nd buld leximinnd lerunt thind s h t cacr cof sestrohe surer ar folenowalldileyo  but anfffo  awe foflubrercearryong lothedineded ithe tothe t llomar ilend or hecissed\n"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df79383",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42c873ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ue wheal theas theme ther the ad dideireassmill whishing in bacestel to i a bessel mo th sing by ashindsecom atch   in hescid thumplaysi an loonvader nous of her mand inaund sed st hinsin and norstain\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b51d3",
   "metadata": {},
   "source": [
    "#### 4grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83b90da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlv               the same the her thing toddarty alonger any of my him soots on repompediansweep abasket headylated and unoccasauntenseof leasorbed so comes and the strement a moor crawn withe gents \n"
     ]
    }
   ],
   "source": [
    "n=4\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf07f1f",
   "metadata": {},
   "source": [
    "#### 5grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2cca2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in the first courteen on the forget so mar           the vittle saw to coministen anxious are the expresent gowanceit nobody ofbarbarabynewalkerbags foot and the first rose stood  north a form i say \n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab31dc",
   "metadata": {},
   "source": [
    "#### 6grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdc5d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " interrupted as force our crunchanted words the confident mr meagles away we looking quite eager veins as a warriors of his favor th advanced speech unwearing forwards  it must now you do it about   m\n"
     ]
    }
   ],
   "source": [
    "n=6\n",
    "modelo, unigr = treinar_ngramas(corpus, n=n)\n",
    "amostra = amostrar_markov(modelo, unigr, n=n, tamanho=tamanho, alfabeto=alfabeto, seed=seed)\n",
    "print(amostra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50390e1c",
   "metadata": {},
   "source": [
    "## Conclusão final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de94e9",
   "metadata": {},
   "source": [
    "Assim como Shannon, parece que à medida que consideramos mais grams o texto vai ganhando “cara” de linguagem, mostrando que de alguma forma, podemos modelar estatísticamente a linguagem. Contudo, temos que confessar que nesse momento, uma modelagem \"simples\" como essa não nos garante nenhum tipo de entendimento ou \"significado\".\n",
    "\n",
    "\n",
    "Ainda na hipótese de Shannon onde a entropia verdadeira da lingua é sempre menor ou igual a de qualquer modelo que busca aproximação, nisso, é como se ainda estivessemos muito \"longe\" desse limite inferior.\n",
    "\n",
    "\n",
    "O que nos leva a pergunta, em um modelo hipotético que tem uma entropia igual ou muito próxima da lingua, o quanto podemos dizer que esse modelo é \"inteligente\". Ou seja, o quanto do mundo real é de fato representado pela língua?. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
